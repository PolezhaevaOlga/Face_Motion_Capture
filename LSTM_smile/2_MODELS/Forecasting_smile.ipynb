{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611074b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\\\Users\\\\olgat\\\\Desktop\\\\Stage Amiens\\\\6_Github\") \n",
    "import functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import IPython\n",
    "import IPython.display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b7280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face area markers\n",
    "def list_to_array(input_list):\n",
    "    np_list=[]\n",
    "    for elem in input_list:\n",
    "        df = pd.read_csv(elem, header=None).fillna(0)\n",
    "#         df = df.iloc[:,[ 40, 41,\t42,\t88,\t89,\t90,\t91,\t92,\t83,\t84,\t85,\t86,\t87,\t74,\t75,\t76,\t77,\t78,\t79,\t80,\t81,\t82,\t72,\t73,\t67, # LEFT\n",
    "#                          45,\t44,\t43,\t46,\t47,\t48,\t49,\t50,\t51,\t52,\t53,\t54,\t55,\t56,\t57,\t58,\t59,\t60,\t61,\t62,\t63,\t64,\t68,\t69,\t65]]\n",
    "        df = df.iloc[:,[ 38, 40, 41, 42, 88, 89, 90, 91, 92, 83, 84, 85, 86, 87, 74, 75, 76, 77, 78, 79, 80, 81, 82, 72, 73, 67,# LEFT\n",
    "                        98, 45, 44, 43, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 68, 69, 65]]\n",
    "\n",
    "        np_array = df.to_numpy()\n",
    "        np_list.append(np.nan_to_num(np_array))\n",
    "    return np_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/olgat/Desktop/Stage Amiens/4 - ML_MoCap/Mvt5/5MhrdP0_cup_M5\"\n",
    "dP0_csv = functions.list_of_files(path)\n",
    "dP0_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27e1d2",
   "metadata": {},
   "source": [
    "#### Preprosessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3392dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dP0_list = list_to_array(dP0_csv)\n",
    "inter_list = functions.list_to_interpolate(dP0_list) # interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffc3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_list, max_value_list, min_value_list = functions.scaled_data2(inter_list) # scaling between 0 and 1\n",
    "scaled_list_f = functions.list_to_denoise(scaled_list, fs=100, fc=15, filters=4) # Butterworth filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f2611",
   "metadata": {},
   "source": [
    "#### Dataset  training, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827bfbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(scaled_list_f)\n",
    "list_train = scaled_list_f[:int(n*0.70)]\n",
    "list_validate = scaled_list_f[int(n*0.70):int(n*0.9)]\n",
    "list_test = scaled_list_f[int(n*0.9):]\n",
    "print(len(list_train))\n",
    "print(len(list_validate))\n",
    "print(len(list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a window for the LSTM algorithm\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps # find end of sequence\n",
    "        if end_ix > len(sequences)-1: # check if we are beyond the dataset\n",
    "            break           \n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :] # put the input and output parts together\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e99ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c890ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(list_data, n_steps):\n",
    "    feature_list =[]\n",
    "    label_list = []\n",
    "    for elem in list_data:\n",
    "        feature, label = split_sequences(elem, n_steps)    \n",
    "        feature_list.append(feature)\n",
    "        label_list.append(label)\n",
    "    feature_list  = np.array(feature_list)\n",
    "    label_list = np.array(label_list)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((feature_list, label_list))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b46e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = make_dataset(list_data = list_train, n_steps = n_steps)\n",
    "dataset_valid = make_dataset(list_data = list_validate, n_steps = n_steps)\n",
    "dataset_test = make_dataset(list_data = list_test, n_steps = n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68bea9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check\n",
    "print(len(list(dataset_valid.as_numpy_iterator())))\n",
    "for elem in dataset_valid:\n",
    "    print(elem)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9514cf34",
   "metadata": {},
   "source": [
    "#### LSTM one step model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = dP0_list[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2413111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model, patience=20):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "                metrics=[tf.metrics.RootMeanSquaredError() ])\n",
    "    \n",
    "    history = model.fit(dataset_train, epochs=150, batch_size=32,\n",
    "                      validation_data=dataset_valid,\n",
    "                      callbacks=[early_stopping])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b94cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(30, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(rate=0.1),\n",
    "    tf.keras.layers.LSTM(30, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(rate=0.1),\n",
    "    tf.keras.layers.LSTM(30, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(rate=0.1),\n",
    "    tf.keras.layers.LSTM(30, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(rate=0.1),\n",
    "    tf.keras.layers.LSTM(30, return_sequences=False),\n",
    "    tf.keras.layers.Dropout(rate=0.1),\n",
    "     # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=num_features,activation='relu')                        \n",
    "])\n",
    "history = compile_and_fit(multi_lstm_model)\n",
    "IPython.display.clear_output()\n",
    "multi_lstm_model.evaluate(dataset_valid, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e81ad78",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc74d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.plot(history.history['val_root_mean_squared_error'])\n",
    "plt.title('model RMSE')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "def create_time_steps(length):\n",
    "    return list(range(-length, 0))\n",
    "def multi_step_plot(history, true_future, prediction, num_marker, num_marker_2 = None):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    num_in = create_time_steps(len(history))\n",
    "    num_out = len(true_future)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(np.arange(num_out), np.array(true_future[:, num_marker:num_marker+1]), 'b-',\n",
    "           label='Real motion')\n",
    "    if prediction.any():\n",
    "        plt.plot(np.arange(num_out), np.array(prediction[:, num_marker:num_marker+1]), 'r',\n",
    "                 label='Predicted motion')\n",
    "    plt.ylim(0,1)    \n",
    "    plt.title(f'Marker {num_marker}')\n",
    "    plt.ylabel('Displacement')\n",
    "    plt.xlabel('Time [sec]')    \n",
    "    plt.legend(loc='upper right')\n",
    "    if num_marker_2 is not None:\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(np.arange(num_out), np.array(true_future[:, num_marker_2:num_marker_2+1]), 'b-',\n",
    "               label='RÃ©el mvt')\n",
    "        if prediction.any():\n",
    "            plt.plot(np.arange(num_out), np.array(prediction[:, num_marker_2:num_marker_2+1]), 'r',\n",
    "                     label='Predicted motion')\n",
    "    plt.ylim(0,1)\n",
    "    plt.title(f'Marker {num_marker_2}')\n",
    "    plt.ylabel('Displacement')\n",
    "    plt.xlabel('Time [sec]')    \n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d79653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x, y in dataset_test.take(1):\n",
    "    for i in range(0,25):\n",
    "        multi_step_plot(x[0], y,multi_lstm_model.predict(x), i,i+25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ff3aa",
   "metadata": {},
   "source": [
    "#### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658777fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse_train, rmse_valid, rmse_test = list(), list(), list()\n",
    "\n",
    "for x, y in dataset_train:\n",
    "    rmse = mean_squared_error(y, multi_lstm_model.predict(x), squared=False)\n",
    "    rmse_train.append(rmse)   \n",
    "rmse_train = np.mean(rmse_train)\n",
    "\n",
    "for x, y in dataset_valid:\n",
    "    rmse = mean_squared_error(y, multi_lstm_model.predict(x), squared=False)\n",
    "    rmse_valid.append(rmse) \n",
    "rmse_valid = np.mean(rmse_valid)\n",
    "\n",
    "for x, y in dataset_test:\n",
    "    rmse = mean_squared_error(y, multi_lstm_model.predict(x), squared=False)\n",
    "    rmse_test.append(rmse) \n",
    "rmse_test = np.mean(rmse_test)\n",
    "\n",
    "rmse_train,rmse_valid,rmse_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65092d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "multi_lstm_model.save(\"lstm_5.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('lstm_5.h5')\n",
    "score_train = model.evaluate(dataset_train, verbose=1)\n",
    "score_val = model.evaluate(dataset_valid, verbose=1)\n",
    "score_test = model.evaluate(dataset_test, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score_train[1]*100))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score_val[1]*100))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a98e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "ÐÑÑÑÑÑÑÐ²ÑÐµÑ",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
